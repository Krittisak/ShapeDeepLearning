\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Tennyson1972,sinha2006face}
\citation{sinha2006face}
\citation{lecun1998gradient}
\citation{NIPS2012_4824}
\citation{Le10tiledconvolutional}
\citation{curto2016can}
\citation{diaconis}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{shape_library}{{1}{3}{A visualization of the various shapes generated. Unless otherwise noted, only spheres and tori were used as a binary decision-making task.\relax }{figure.caption.1}{}}
\newlabel{shape_exemplars_to}{{2}{4}{Examples of toruses with the various distortions applied individually, along with the different sampling frequencies.\relax }{figure.caption.2}{}}
\newlabel{shape_exemplars_sp}{{3}{4}{Examples of spheres with the various distortions applied individually, along with the different sampling frequencies.\relax }{figure.caption.3}{}}
\citation{chollet2015keras}
\citation{Prechelt2012}
\newlabel{distortion-settings}{{4}{5}{Input values for each of the nine distortions applied to the shapes.\relax }{figure.caption.4}{}}
\newlabel{voxel-example}{{5}{5}{In this 2D example, the surface of a shape passes more through Voxel 1 than through Voxel 2, resulting in 6 points sampled for Voxel 1 and 2 points sampled for Voxel 2. Using the \textit {float-based approach}, the feature corresponding to Voxel 1 would have $3\times $ the input value as Voxel 2. Using the \textit {binary} approach, both would have input values of 1.\relax }{figure.caption.5}{}}
\newlabel{structure}{{6}{5}{Structure of the CNN. Note that the second convolutional layer, Conv 2, is optional and thus grayed-out.\relax }{figure.caption.7}{}}
\newlabel{CNN_params}{{1}{6}{Summary of CNN parameters\relax }{table.caption.6}{}}
\newlabel{table:results1}{{2}{7}{A description of the different parameters and results for a neural net with a single convolutional layer. \textcolor {blue}{Results in blue indicate a float-based approach.}\relax }{table.caption.8}{}}
\newlabel{table:results2}{{3}{7}{A description of the different parameters and results for a neural net with two convolutional layers. \textcolor {blue}{No tests were run with a float-based approach.}\relax }{table.caption.9}{}}
\newlabel{results-graph}{{7}{7}{Testing accuracy plotted against sampling rate \textit {(top)}, and time-to-convergence plotted against sampling rate $bottom$.\relax }{figure.caption.10}{}}
\newlabel{ROCgraph}{{8}{8}{ROC curves for both a high and low-performing parameter settings.\relax }{figure.caption.11}{}}
\newlabel{confusion-binary-bad}{{9}{8}{Confusion matrix for \textit {all (except poly)} with a sampling rate of 10000 and a single convolutional layer\relax }{figure.caption.12}{}}
\newlabel{confusion-binary-good}{{10}{8}{Confusion matrix for \textit {translation} with a sampling rate of 10000 and a single convolutional layer.\relax }{figure.caption.13}{}}
\citation{dietterich1995solving}
\newlabel{multiclass_results}{{4}{10}{Accuracy and epochs before early stopping for standard training size and double training size runs.\relax }{table.caption.14}{}}
\newlabel{multiclassconfusion}{{11}{10}{A confusion matrix for the 5-class discrimination task.\relax }{figure.caption.15}{}}
\citation{Le10tiledconvolutional}
\citation{symnets}
\citation{goodfellow2016nips}
\citation{kataoka2016image}
\bibdata{writeup}
\bibcite{chollet2015keras}{{1}{2015}{{Chollet et~al.}}{{}}}
\bibcite{curto2016can}{{2}{2016}{{Curto}}{{}}}
\bibcite{diaconis}{{3}{2012}{{Diaconis et~al.}}{{Diaconis, Holmes, and Shashahani}}}
\bibcite{dietterich1995solving}{{4}{1995}{{Dietterich \& Bakiri}}{{Dietterich and Bakiri}}}
\bibcite{symnets}{{5}{2014}{{Gens \& Domingos}}{{Gens and Domingos}}}
\bibcite{goodfellow2016nips}{{6}{2016}{{Goodfellow}}{{}}}
\bibcite{kataoka2016image}{{7}{2016}{{Kataoka et~al.}}{{Kataoka, Matsubara, and Uehara}}}
\bibcite{NIPS2012_4824}{{8}{2012}{{Krizhevsky et~al.}}{{Krizhevsky, Sutskever, and Hinton}}}
\bibcite{Le10tiledconvolutional}{{9}{2010}{{Le et~al.}}{{Le, Ngiam, Chen, Chia, Koh, and Ng}}}
\bibcite{lecun1998gradient}{{10}{1998}{{LeCun et~al.}}{{LeCun, Bottou, Bengio, and Haffner}}}
\bibcite{Prechelt2012}{{11}{2012}{{Prechelt}}{{}}}
\bibcite{sinha2006face}{{12}{2006}{{Sinha et~al.}}{{Sinha, Balas, Ostrovsky, and Russell}}}
\bibcite{Tennyson1972}{{13}{1972}{{Tennyson et~al.}}{{Tennyson, Woolley, and Merrill}}}
\bibstyle{icml2017}
